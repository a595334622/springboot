#服务端口
server.port=80

#springcloud
management.security.enabled=false
management.port=54001

#数据源     mysql
spring.datasource.username=root
spring.datasource.password=gfs_1998
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://bj-cdb-fsqnguuv.sql.tencentcdb.com:63505/test?useUnicode=true&characterEncoding=UTF-8
#    h2   (sql基本与MySQL相同)
#spring.datasource.url = jdbc:h2:file:D:/java/h2database
#spring.datasource.driverClassName =org.h2.Driver
#spring.datasource.username = sa
#spring.datasource.password = 

#网页编码
spring.http.encoding.force=true
spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
server.tomcat.uri-encoding=UTF-8
#日志
logging.level.root=info

# REDIS (RedisProperties)
spring.redis.database=0
spring.redis.host=140.143.192.167
spring.redis.port=6389
spring.redis.pool.max-active=8
spring.redis.pool.max-wait=-1
spring.redis.pool.max-idle=8
spring.redis.pool.min-idle=0
spring.redis.timeout=0

#activemq
spring.activemq.broker-url=tcp://140.143.192.167:61616
spring.activemq.pool.user=admin
spring.activemq.pool.password=admin
spring.activemq.pool.enabled=false
#spring.activemq.in-memory=false
#spring.activemq.pool.enabled=true
#spring.activemq.pool.max-connections=100
#spring.activemq.send-timeout=3000

#dubbo 
spring.dubbo.application.id=spring-boot
spring.dubbo.server=true
spring.dubbo.application.name=spring-boot
spring.dubbo.registry.address=zookeeper://140.143.192.167:2181
spring.dubbo.protocol.name=dubbo
spring.dubbo.protocol.port=20880
spring.dubbo.protocol.status=server
spring.dubbo.scan=com.wh.api.service.impl

#============== kafka ===================
#spring.kafka.bootstrap-servers=localhost:9092
#=============== provider  =======================
#spring.kafka.producer.retries=0
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
#spring.kafka.consumer.group-id=test-consumer-group
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

